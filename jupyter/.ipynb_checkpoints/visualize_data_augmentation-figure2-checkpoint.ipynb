{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc7879f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from open3d.j_visualizer import JVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a391a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "from torchsparse import SparseTensor\n",
    "from torchsparse.utils.collate import sparse_collate_fn\n",
    "from torchsparse.utils.quantize import sparse_quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43e5dd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErasorCarlaInternal:\n",
    "\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 voxel_size,\n",
    "                 num_points,\n",
    "                 visualize,\n",
    "                 split,\n",
    "                 sample_stride=1,\n",
    "                 submit=False,\n",
    "                 google_mode=True,\n",
    "                 window=10,\n",
    "                 radius=50,\n",
    "                 map_root='testing_map/v0.1'):\n",
    "        if submit:\n",
    "            trainval = True\n",
    "        else:\n",
    "            trainval = False\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self.voxel_size = voxel_size\n",
    "        self.num_points = num_points\n",
    "        self.sample_stride = sample_stride\n",
    "        self.google_mode = google_mode\n",
    "        self.window = window\n",
    "        self.visualize = visualize\n",
    "        self.radius = radius\n",
    "        self.map_root = map_root\n",
    "        self.seqs = []\n",
    "        if split == 'train':\n",
    "            self.seqs = [\n",
    "                'scenario2', \n",
    "                'scenario3', \n",
    "                'scenario5', 'scenario8',\n",
    "            ]\n",
    "\n",
    "        elif self.split == 'val':\n",
    "            self.seqs = [\n",
    "                'scenario6',\n",
    "            ]\n",
    "        elif self.split == 'test':\n",
    "            self.seqs = [\n",
    "               'scenario6',\n",
    "            ]\n",
    "\n",
    "        self.map_files = dict()\n",
    "        self.files = []\n",
    "        \n",
    "        \n",
    "        # get scan and map data list\n",
    "        for seq in self.seqs:\n",
    "            self.map_files[seq] = os.path.join(self.root, \"testing_map/v0.1\", seq, 'map.npy')\n",
    "            self.map_erasor_files[seq] = os.path.join(self.root, \"testing_map/v0.1_erasor\", seq, 'map.npy')\n",
    "            seq_files = sorted(os.listdir(os.path.join(self.root, 'testing_data', seq, 'global_npz')))\n",
    "            seq_files = seq_files[(self.window + 1) // 2 - 1: - (1 + self.window // 2)]\n",
    "\n",
    "            seq_files = [os.path.join(self.root, 'testing_data', seq, 'global_npz', x) for x in seq_files]\n",
    "            self.files.extend(seq_files)\n",
    "\n",
    "        # get map_data\n",
    "        self.map = dict()\n",
    "        for seq, map_file in self.map_files.items():\n",
    "            map_ = np.load(map_file)\n",
    "            # map = generate_voxels(map_, voxel_size=self.voxel_size)\n",
    "            self.map[seq] = map_.astype(np.float32)\n",
    "        \n",
    "        # get map_erasor_data\n",
    "        self.map_erasor = dict()\n",
    "        for seq, map_erasor_file in self.map_erasor_files.items():\n",
    "            map_erasor_ = np.load(map_erasor_file)\n",
    "            # map = generate_voxels(map_, voxel_size=self.voxel_size)\n",
    "            self.map_erasor[seq] = map_erasor_.astype(np.float32)\n",
    "\n",
    "        if self.sample_stride > 1:\n",
    "            self.files = self.files[::self.sample_stride]\n",
    "\n",
    "        self.num_classes = 2\n",
    "        self.angle = 0.0\n",
    "\n",
    "    def set_angle(self, angle):\n",
    "        self.angle = angle\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        index = 370\n",
    "        # get scan_data\n",
    "        scan = np.load(self.files[index])\n",
    "        block_ = scan['arr_0'].astype(np.float32) \n",
    "        odom = scan['arr_1'].astype(np.float32)\n",
    "\n",
    "        if self.window > 1:\n",
    "            file_name = os.path.basename(self.files[index])\n",
    "            file_dir = os.path.dirname(self.files[index])\n",
    "            file_name_wo_ext = os.path.splitext(file_name)[0]\n",
    "            file_int = int(file_name_wo_ext)\n",
    "            file_int_list = list(range(file_int - (self.window + 1) // 2 + 1, file_int + self.window // 2 + 1, 1))\n",
    "            file_str_list = [file_dir + \"/\" + str(i).zfill(6) + \".npz\" for i in file_int_list]\n",
    "            block_multi = []\n",
    "            for file in file_str_list:\n",
    "                scan_ = np.load(file)\n",
    "                block_single = scan_['arr_0'].astype(np.float32)\n",
    "                block_multi.extend(block_single)\n",
    "            block_ = np.asarray(block_multi)\n",
    "            # radius search w.r.t the odom of scan data\n",
    "            block_ = block_[np.sum(np.square(block_[:, :3] - odom), axis=-1) < self.radius*self.radius]\n",
    "        \n",
    "\n",
    "#         block_debug = block_[:, 3]\n",
    "        \n",
    "        # get map_data\n",
    "        scenario = self.files[index]\n",
    "        scenario = scenario.split(\"/\")[-3]\n",
    "        map_ = self.map[scenario]\n",
    "        # radius search w.r.t the odom of scan data\n",
    "        map_ = map_[np.sum(np.square(map_[:, :3] - odom), axis=-1) < self.radius*self.radius]\n",
    "\n",
    "        block = np.zeros_like(block_)\n",
    "        map = np.zeros_like(map_)\n",
    "\n",
    "        if 'train' in self.split:\n",
    "            # data augmentation on the train dataset\n",
    "            theta = np.random.uniform(0, 2 * np.pi)\n",
    "            scale_factor = np.random.uniform(0.95, 1.05)\n",
    "            rot_mat = np.array([[np.cos(theta), np.sin(theta), 0],\n",
    "                                [-np.sin(theta),\n",
    "                                 np.cos(theta), 0], [0, 0, 1]])\n",
    "\n",
    "            block[:, :3] = np.dot(block_[:, :3], rot_mat) * scale_factor\n",
    "            map[:, :3] = np.dot(map_[:, :3], rot_mat) * scale_factor\n",
    "\n",
    "        else:\n",
    "            theta = self.angle\n",
    "            transform_mat = np.array([[np.cos(theta),\n",
    "                                       np.sin(theta), 0],\n",
    "                                      [-np.sin(theta),\n",
    "                                       np.cos(theta), 0], [0, 0, 1]])\n",
    "            block[...] = block_[...]\n",
    "            block[:, :3] = np.dot(block[:, :3], transform_mat)\n",
    "            map[:, :3] = np.dot(map_[:, :3], transform_mat)\n",
    "        \n",
    "        block[: ,3] = block_[:, 3]\n",
    "        map[:, 3] = map_[:, 3]\n",
    "            \n",
    "#         # self-supervised dynamic label\n",
    "#         center_x = np.mean(block[:, 0])\n",
    "#         center_y = np.mean(block[:, 1])\n",
    "#         sspoints_ = np.mgrid[center_x+2:center_x+3:self.voxel_size, center_y-2:center_y+3:self.voxel_size, 0:2:self.voxel_size]\n",
    "#         sspoints = sspoints_.reshape(3, -1).T\n",
    "#         sslabels = np.ones([np.shape(sspoints)[0], 1],)\n",
    "#         ssblock = np.concatenate((sspoints, sslabels), axis=1)\n",
    "        \n",
    "#         block = np.concatenate((block, ssblock), axis=0)\n",
    "        \n",
    "\n",
    "        # parsing the original label to the dynamic label\n",
    "        block[:, 3] = (block_[:, 3] == 1)\n",
    "        if self.map_root == \"testing_map/v0.1_erasor\":\n",
    "            map[:, 3] = (map_[:, 3] == 700)\n",
    "        else:\n",
    "            map[:, 3] = (map_[:, 3] == 1)\n",
    "#         block[:, 3] = (block[:, 3] != 0)\n",
    "#         map[:, 3] = (map[:, 3] != 0)\n",
    "#         map[:, 3] = 0\n",
    "        \n",
    "#         # get point and voxel in the format of sparse torch tensor\n",
    "#         map_data = self.get_point_voxel(map[:, :3], map[:, 3], index)\n",
    "#         scan_data = self.get_point_voxel(block[:, :3], block[:, 3], index)\n",
    "\n",
    "        # get original point and voxel\n",
    "        map_data = self.get_original_point(map[:, :3], map[:, 3], index)\n",
    "        scan_data = self.get_original_point(block[:, :3], block[:, 3], index)\n",
    "\n",
    "#         return map_data\n",
    "        return map_data, scan_data\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(inputs):\n",
    "        return sparse_collate_fn(inputs)\n",
    "    \n",
    "    def get_original_point(self, block, labels_, index):\n",
    "        pc_ = np.round(block / self.voxel_size).astype(np.int32)\n",
    "        \n",
    "        # normalize the point for visualization\n",
    "        pc_ -= pc_.min(0, keepdims=1)\n",
    "        \n",
    "        _, inds, inverse_map = sparse_quantize(pc_,\n",
    "                                               return_index=True,\n",
    "                                               return_inverse=True)\n",
    "        \n",
    "        if len(inds) > self.num_points:\n",
    "                inds = np.random.choice(inds, self.num_points, replace=False)\n",
    "    \n",
    "        pc = pc_[inds]\n",
    "        labels = labels_[inds]\n",
    "\n",
    "        feed_dict = {\n",
    "            'pc_': pc_,\n",
    "            'targets_': labels_,\n",
    "            'file_name': self.files[index],\n",
    "            'pc': pc,\n",
    "            'targets': labels,\n",
    "            'inds': inds,\n",
    "            'inverse_map': inverse_map,\n",
    "            'file_name': self.files[index]\n",
    "        }\n",
    "        \n",
    "        return feed_dict\n",
    "    \n",
    "    \n",
    "    def get_point_voxel(self, block, labels_, index):\n",
    "        pc_ = np.round(block[:, :3] / self.voxel_size).astype(np.int32)\n",
    "        pc_ -= pc_.min(0, keepdims=1)\n",
    "\n",
    "        feat_ = block\n",
    "\n",
    "        _, inds, inverse_map = sparse_quantize(pc_,\n",
    "                                               return_index=True,\n",
    "                                               return_inverse=True)\n",
    "\n",
    "        if 'train' in self.split:\n",
    "            if len(inds) > self.num_points:\n",
    "                inds = np.random.choice(inds, self.num_points, replace=False)\n",
    "\n",
    "        pc = pc_[inds]\n",
    "        feat = feat_[inds]\n",
    "        labels = labels_[inds]\n",
    "        lidar = SparseTensor(feat, pc)\n",
    "        labels = SparseTensor(labels, pc)\n",
    "        labels_ = SparseTensor(labels_, pc_)\n",
    "        inverse_map = SparseTensor(inverse_map, pc_)\n",
    "\n",
    "        if self.visualize == False:\n",
    "            feed_dict = {\n",
    "            'lidar': lidar,\n",
    "            'targets': labels,\n",
    "            'targets_mapped': labels_,\n",
    "            'inverse_map': inverse_map,\n",
    "            'file_name': self.files[index]\n",
    "        }\n",
    "\n",
    "        else:\n",
    "            feed_dict = {\n",
    "                'pc': block[:, :3],\n",
    "                'label': labels_,\n",
    "                'lidar': lidar,\n",
    "                'targets': labels,\n",
    "                'targets_mapped': labels_,\n",
    "                'inverse_map': inverse_map,\n",
    "                'file_name': self.files[index]\n",
    "            }\n",
    "\n",
    "        return feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa00e266",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/ws/data/erasor_carla/carla_dataset\"\n",
    "voxel_size = 0.1\n",
    "num_points = 30000\n",
    "visualize = True\n",
    "sample_stride = 1\n",
    "split = \"train\"\n",
    "submit = True\n",
    "window = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "15d641ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ErasorCarlaInternal(root, voxel_size, num_points, visualize, split, submit, window=window)\n",
    "map_data, scan_data = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f7850ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_points(points, labels, label2color):    \n",
    "    points = (points - points.mean()) / points.std()\n",
    "    colors = np.array([label2color[x] for x in labels])\n",
    "    \n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    visualizer = JVisualizer()\n",
    "    visualizer.add_geometry(pcd)\n",
    "    visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "777061fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec462d39fca4b85b4fc982c0ae3b14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JVisualizer with 1 geometries"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label2color = {0: (1.0, 0.0, 0.0), 1: (0.0, 0.0, 1.0), 2:(0.0, 0.0, 1.0)}\n",
    "visualize_points(scan_data['pc'], scan_data['targets'], label2color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7b0a3a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label2color = {0: (1.0, 0.0, 0.0), 1: (1.0, 0.0, 0.0)}\n",
    "# visualize_points(scan_data['pc'], scan_data['targets'], label2color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "608d7a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f08e0d4b23b4c0b84f6c2b5bd388b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JVisualizer with 1 geometries"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label2color = {0: (1.0, 0.0, 0.0), 1: (0.0, 0.0, 1.0), 2:(0.0, 0.0, 1.0)}\n",
    "visualize_points(map_data['pc'], map_data['targets'], label2color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8ecaf317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_data['targets'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "219294e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label2color = {0: (1.0, 0.0, 0.0), 1: (1.0, 0.0, 0.0), 2:(0.0, 0.0, 1.0)}\n",
    "# visualize_points(map_data['pc'], map_data['targets'], label2color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "690daecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "window=1\n",
    "dataset = ErasorCarlaInternal(root, voxel_size, num_points, visualize, split, submit, window=window, map_root=\"testing_map/v0.1_erasor\")\n",
    "map_data, scan_data = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f9489df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17caeb19bf4d4364b6b161982a3ea61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JVisualizer with 1 geometries"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label2color = {0: (1.0, 0.0, 0.0), 1: (0.0, 0.0, 1.0), 2:(0.0, 0.0, 1.0)}\n",
    "visualize_points(map_data['pc'], map_data['targets'], label2color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "995117f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13270e150574fc4a1f3189de53cdc50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JVisualizer with 1 geometries"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label2color = {0: (1.0, 0.0, 0.0), 1: (0.0, 0.0, 1.0), 2:(0.0, 0.0, 1.0)}\n",
    "visualize_points(scan_data['pc'], scan_data['targets'], label2color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e587a4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4207e03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd453233fba43df840a8f9ad4a98737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JVisualizer with 1 geometries"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "visualizer = JVisualizer()\n",
    "visualizer.add_geometry(pcd)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e7ea23e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o3d.io.write_point_cloud(\"/ws/external/visualization_results/scan_window1.pcd\", pcd)\n",
    "o3d.io.write_point_cloud(\"/ws/external/visualization_results/scan_window1.ply\", pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1f41f322",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_ = map_data['pc']\n",
    "points = (points_ - points_.mean()) / points_.std()\n",
    "labels = map_data['targets']\n",
    "colors = np.array([label2color[x] for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3fa32b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a54d3a3d5040208f12db5368b246f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JVisualizer with 1 geometries"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "visualizer = JVisualizer()\n",
    "visualizer.add_geometry(pcd)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4082f44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o3d.io.write_point_cloud(\"/ws/external/visualization_results/map.pcd\", pcd)\n",
    "o3d.io.write_point_cloud(\"/ws/external/visualization_results/map.ply\", pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946da925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "03fa1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sspoints_ = np.mgrid[1:3:0.2, 2:6:0.2, 0:2:0.2]\n",
    "sspoints = sspoints_.reshape(3, -1).T\n",
    "sslabels = np.ones([np.shape(sspoints)[0], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5dd33be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.18889817,  0.44287013, -1.18523127],\n",
       "       [-1.18889817,  0.45387082, -1.18523127],\n",
       "       [-1.18523127,  0.39886739, -1.18523127],\n",
       "       ...,\n",
       "       [ 5.8       ,  4.8       ,  1.4       ],\n",
       "       [ 5.8       ,  4.8       ,  1.6       ],\n",
       "       [ 5.8       ,  4.8       ,  1.8       ]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "79e82247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 3)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(sspoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "04a7b2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(sslabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7ceeafe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssblock = np.concatenate((sspoints, sslabels), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bd40667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.concatenate((points, sspoints), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c7d2c991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.18889817,  0.44287013, -1.18523127],\n",
       "       [-1.18889817,  0.45387082, -1.18523127],\n",
       "       [-1.18523127,  0.39886739, -1.18523127],\n",
       "       ...,\n",
       "       [ 5.8       ,  4.8       ,  1.4       ],\n",
       "       [ 5.8       ,  4.8       ,  1.6       ],\n",
       "       [ 5.8       ,  4.8       ,  1.8       ]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a1d347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15072fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b12b6be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb83b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507bf9fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
