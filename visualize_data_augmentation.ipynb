{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fc7879f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from open3d.j_visualizer import JVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3a391a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "from torchsparse import SparseTensor\n",
    "from torchsparse.utils.collate import sparse_collate_fn\n",
    "from torchsparse.utils.quantize import sparse_quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43e5dd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErasorCarlaInternal:\n",
    "\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 voxel_size,\n",
    "                 num_points,\n",
    "                 visualize,\n",
    "                 split,\n",
    "                 sample_stride=1,\n",
    "                 submit=False,\n",
    "                 google_mode=True,\n",
    "                 window=10,\n",
    "                 radius=50):\n",
    "        if submit:\n",
    "            trainval = True\n",
    "        else:\n",
    "            trainval = False\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self.voxel_size = voxel_size\n",
    "        self.num_points = num_points\n",
    "        self.sample_stride = sample_stride\n",
    "        self.google_mode = google_mode\n",
    "        self.window = window\n",
    "        self.visualize = visualize\n",
    "        self.radius = radius\n",
    "        self.seqs = []\n",
    "        if split == 'train':\n",
    "            self.seqs = [\n",
    "                'scenario2', 'scenario3', 'scenario5', 'scenario8',\n",
    "            ]\n",
    "\n",
    "        elif self.split == 'val':\n",
    "            self.seqs = [\n",
    "                'scenario6',\n",
    "            ]\n",
    "        elif self.split == 'test':\n",
    "            self.seqs = [\n",
    "               'scenario6',\n",
    "            ]\n",
    "\n",
    "        self.map_files = dict()\n",
    "        self.files = []\n",
    "\n",
    "        # get scan and map data list\n",
    "        for seq in self.seqs:\n",
    "            self.map_files[seq] = os.path.join(self.root, 'testing_map/v0.1', seq, 'map.npy')\n",
    "            seq_files = sorted(os.listdir(os.path.join(self.root, 'testing_data', seq, 'global_npz')))\n",
    "            seq_files = seq_files[(self.window + 1) // 2 - 1: - (self.window // 2) + 1]\n",
    "\n",
    "            seq_files = [os.path.join(self.root, 'testing_data', seq, 'global_npz', x) for x in seq_files]\n",
    "            self.files.extend(seq_files)\n",
    "\n",
    "        # get map_data\n",
    "        self.map = dict()\n",
    "        for seq, map_file in self.map_files.items():\n",
    "            map_ = np.load(map_file)\n",
    "            # map = generate_voxels(map_, voxel_size=self.voxel_size)\n",
    "            self.map[seq] = map_.astype(np.float32)\n",
    "\n",
    "        if self.sample_stride > 1:\n",
    "            self.files = self.files[::self.sample_stride]\n",
    "\n",
    "        self.num_classes = 2\n",
    "        self.angle = 0.0\n",
    "\n",
    "    def set_angle(self, angle):\n",
    "        self.angle = angle\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # get scan_data\n",
    "        scan = np.load(self.files[index])\n",
    "        block_ = scan['arr_0'].astype(np.float32)\n",
    "        odom = scan['arr_1'].astype(np.float32)\n",
    "\n",
    "        if self.window > 1:\n",
    "            file_name = os.path.basename(self.files[index])\n",
    "            file_dir = os.path.dirname(self.files[index])\n",
    "            file_name_wo_ext = os.path.splitext(file_name)[0]\n",
    "            file_int = int(file_name_wo_ext)\n",
    "            file_int_list = list(range(file_int - (self.window + 1) // 2 + 1, file_int + self.window // 2 + 1, 1))\n",
    "            file_str_list = [file_dir + \"/\" + str(i).zfill(6) + \".npz\" for i in file_int_list]\n",
    "            block_ = []\n",
    "            for file in file_str_list:\n",
    "                scan_ = np.load(file)\n",
    "                block_single = scan_['arr_0'].astype(np.float32)\n",
    "                block_.extend(block_single)\n",
    "            block_ = np.asarray(block_)\n",
    "            # radius search w.r.t the odom of scan data\n",
    "            block_ = block_[np.sum(np.square(block_[:, :3] - odom), axis=-1) < self.radius*self.radius]\n",
    "\n",
    "        # get map_data\n",
    "        scenario = self.files[index]\n",
    "        scenario = scenario.split(\"/\")[-3]\n",
    "        map_ = self.map[scenario]\n",
    "        # radius search w.r.t the odom of scan data\n",
    "        map_ = map_[np.sum(np.square(map_[:, :3] - odom), axis=-1) < self.radius*self.radius]\n",
    "        \n",
    "        # get pesudo label with ERASOR\n",
    "        \"\"\"\n",
    "        def get_pseudo_label(self, map_, block_, **kwargs):\n",
    "            # return dynamic and static labels of map\n",
    "            return map_[:, 3]\n",
    "        pseudo_label = self.get_pseudo_label(map_, block_, **kwargs)\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        block = np.zeros_like(block_)\n",
    "        map = np.zeros_like(map_)\n",
    "        \n",
    "\n",
    "        if 'train' in self.split:\n",
    "            # data augmentation on the train dataset\n",
    "            theta = np.random.uniform(0, 2 * np.pi)\n",
    "            scale_factor = np.random.uniform(0.95, 1.05)\n",
    "            rot_mat = np.array([[np.cos(theta), np.sin(theta), 0],\n",
    "                                [-np.sin(theta),\n",
    "                                 np.cos(theta), 0], [0, 0, 1]])\n",
    "\n",
    "            block[:, :3] = np.dot(block_[:, :3], rot_mat) * scale_factor\n",
    "            map[:, :3] = np.dot(map_[:, :3], rot_mat) * scale_factor\n",
    "\n",
    "        else:\n",
    "            theta = self.angle\n",
    "            transform_mat = np.array([[np.cos(theta),\n",
    "                                       np.sin(theta), 0],\n",
    "                                      [-np.sin(theta),\n",
    "                                       np.cos(theta), 0], [0, 0, 1]])\n",
    "            block[...] = block_[...]\n",
    "            block[:, :3] = np.dot(block[:, :3], transform_mat)\n",
    "            map[:, :3] = np.dot(map_[:, :3], transform_mat)\n",
    "            \n",
    "#         # self-supervised dynamic label\n",
    "#         center_x = np.mean(block[:, 0])\n",
    "#         center_y = np.mean(block[:, 1])\n",
    "#         sspoints_ = np.mgrid[center_x+2:center_x+3:self.voxel_size, center_y-2:center_y+3:self.voxel_size, 0:2:self.voxel_size]\n",
    "#         sspoints = sspoints_.reshape(3, -1).T\n",
    "#         sslabels = np.ones([np.shape(sspoints)[0], 1],)\n",
    "#         ssblock = np.concatenate((sspoints, sslabels), axis=1)\n",
    "        \n",
    "#         block = np.concatenate((block, ssblock), axis=0)\n",
    "        \n",
    "\n",
    "        # parsing the original label to the dynamic label\n",
    "        block[:, 3] = (block[:, 3] == 1)\n",
    "        map[:, 3] = (map[:, 3] == 1)\n",
    "        \n",
    "#         # get point and voxel in the format of sparse torch tensor\n",
    "#         map_data = self.get_point_voxel(map[:, :3], map[:, 3], index)\n",
    "#         scan_data = self.get_point_voxel(block[:, :3], block[:, 3], index)\n",
    "        \n",
    "        # get original point and voxel\n",
    "        map_data = self.get_original_point(map[:, :3], map[:, 3], index)\n",
    "        scan_data = self.get_original_point(block[:, :3], block[:, 3], index)\n",
    "\n",
    "#         return map_data\n",
    "        return map_data, scan_data\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(inputs):\n",
    "        return sparse_collate_fn(inputs)\n",
    "    \n",
    "    def get_original_point(self, block, labels_, index):\n",
    "        pc_ = np.round(block[:, :3] / self.voxel_size).astype(np.int32)\n",
    "        \n",
    "#         # normalize the point for visualization\n",
    "#         pc_ = (pc_ - np.mean(pc_)) / np.std(pc_)\n",
    "        pc_ -= pc_.min(0, keepdims=1)\n",
    "        \n",
    "        _, inds, inverse_map = sparse_quantize(pc_,\n",
    "                                               return_index=True,\n",
    "                                               return_inverse=True)\n",
    "        \n",
    "        if len(inds) > self.num_points:\n",
    "                inds = np.random.choice(inds, self.num_points, replace=False)\n",
    "    \n",
    "        pc = pc_[inds]\n",
    "        labels = labels_[inds]\n",
    "        \n",
    "        \n",
    "        feed_dict = {\n",
    "            'pc_': pc_,\n",
    "            'targets_': labels_,\n",
    "            'file_name': self.files[index],\n",
    "            'pc': pc,\n",
    "            'targets': labels,\n",
    "            'inds': inds,\n",
    "            'inverse_map': inverse_map,\n",
    "            'file_name': self.files[index]\n",
    "        }\n",
    "        return feed_dict\n",
    "    \n",
    "    def get_point_voxel(self, block, labels_, index):\n",
    "        pc_ = np.round(block[:, :3] / self.voxel_size).astype(np.int32)\n",
    "        pc_ -= pc_.min(0, keepdims=1)\n",
    "\n",
    "        feat_ = block\n",
    "\n",
    "        _, inds, inverse_map = sparse_quantize(pc_,\n",
    "                                               return_index=True,\n",
    "                                               return_inverse=True)\n",
    "\n",
    "        if 'train' in self.split:\n",
    "            if len(inds) > self.num_points:\n",
    "                inds = np.random.choice(inds, self.num_points, replace=False)\n",
    "\n",
    "        pc = pc_[inds]\n",
    "        feat = feat_[inds]\n",
    "        labels = labels_[inds]\n",
    "        lidar = SparseTensor(feat, pc)\n",
    "        labels = SparseTensor(labels, pc)\n",
    "        labels_ = SparseTensor(labels_, pc_)\n",
    "        inverse_map = SparseTensor(inverse_map, pc_)\n",
    "\n",
    "        if self.visualize == False:\n",
    "            feed_dict = {\n",
    "            'lidar': lidar,\n",
    "            'targets': labels,\n",
    "            'targets_mapped': labels_,\n",
    "            'inverse_map': inverse_map,\n",
    "            'file_name': self.files[index]\n",
    "        }\n",
    "\n",
    "        else:\n",
    "            feed_dict = {\n",
    "                'pc': block[:, :3],\n",
    "                'label': labels_,\n",
    "                'lidar': lidar,\n",
    "                'targets': labels,\n",
    "                'targets_mapped': labels_,\n",
    "                'inverse_map': inverse_map,\n",
    "                'file_name': self.files[index]\n",
    "            }\n",
    "\n",
    "        return feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "aa00e266",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/ws/data/erasor_carla/carla_dataset\"\n",
    "voxel_size = 0.1\n",
    "num_points = 300000\n",
    "visualize = True\n",
    "sample_stride = 1\n",
    "split = \"train\"\n",
    "submit = True\n",
    "window = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "15d641ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ErasorCarlaInternal(root, voxel_size, num_points, visualize, split, submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "70131fe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "map_data, scan_data = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "db40e27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pc_', 'targets_', 'file_name', 'pc', 'targets', 'inds', 'inverse_map'])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3c313907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape(scan_data['pc_'])\n",
    "# np.shape(scan_data['pc'][scan_data['inverse_map']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "af296dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_ = scan_data['pc']\n",
    "labels = scan_data['targets']\n",
    "orig_points = scan_data['pc'][scan_data['inverse_map']]\n",
    "orig_labels = scan_data['targets'][scan_data['inverse_map']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "40573949",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = (points_ - points_.mean()) / points_.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d8a82300",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2color = {0: (1.0, 0.0, 0.0), 1: (0.0, 0.0, 1.0), 2:(0.0, 0.0, 1.0)}\n",
    "colors = np.array([map_color[x] for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "777061fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695b33f8828b40adb3033285308ace97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JVisualizer with 1 geometries"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "visualizer = JVisualizer()\n",
    "visualizer.add_geometry(pcd)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e3bbb631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211160, 3)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "608d7a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpoints_ = map_data['pc']\n",
    "mlabels = map_data['targets']\n",
    "# orig_points = map_data['pc'][map_data['inverse_map']]\n",
    "# orig_labels = map_data['targets'][map_data['inverse_map']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4f312cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpoints = (mpoints_ - mpoints_.mean()) / mpoints_.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "30268d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2color = {0: (1.0, 0.0, 0.0), 1: (0.0, 0.0, 1.0), 2:(0.0, 0.0, 1.0)}\n",
    "mcolors = np.array([map_color[x] for x in mlabels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b4207e03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7750edf3f67b409988569c21bc8a63d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JVisualizer with 1 geometries"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(mpoints)\n",
    "pcd.colors = o3d.utility.Vector3dVector(mcolors)\n",
    "visualizer = JVisualizer()\n",
    "visualizer.add_geometry(pcd)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "60766546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 3)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(mpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "03fa1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sspoints_ = np.mgrid[1:3:0.2, 2:6:0.2, 0:2:0.2]\n",
    "sspoints = sspoints_.reshape(3, -1).T\n",
    "sslabels = np.ones([np.shape(sspoints)[0], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5dd33be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.19546345,  0.59915196, -1.19161234],\n",
       "       [-1.18391013,  0.59530085, -1.19161234],\n",
       "       [-1.17235681,  0.58759864, -1.19161234],\n",
       "       ...,\n",
       "       [ 1.97399681, -0.34822012, -1.01831257],\n",
       "       [ 1.99710345, -0.29045353, -1.01831257],\n",
       "       [ 1.99710345, -0.28660243, -1.01831257]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "79e82247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 3)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(sspoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "04a7b2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(sslabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7ceeafe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssblock = np.concatenate((sspoints, sslabels), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bd40667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.concatenate((points, sspoints), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c7d2c991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.18889817,  0.44287013, -1.18523127],\n",
       "       [-1.18889817,  0.45387082, -1.18523127],\n",
       "       [-1.18523127,  0.39886739, -1.18523127],\n",
       "       ...,\n",
       "       [ 5.8       ,  4.8       ,  1.4       ],\n",
       "       [ 5.8       ,  4.8       ,  1.6       ],\n",
       "       [ 5.8       ,  4.8       ,  1.8       ]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a1d347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15072fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b12b6be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb83b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507bf9fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
